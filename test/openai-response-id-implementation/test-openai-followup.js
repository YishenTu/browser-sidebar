// npm i openai dotenv
import OpenAI from "openai";
import dotenv from "dotenv";
import fs from "fs/promises";
import path from "path";

// Load environment variables
dotenv.config();

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// System prompt for consistent behavior
const SYSTEM_PROMPT = `
ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨ã€ç®€æ´çš„ä¸­æ–‡åŠ©ç†ã€‚è¾“å‡ºç»“æ„ï¼šå…ˆç»“è®ºï¼Œå†ä¾æ®ï¼Œæœ€åç»™ä¸ç¡®å®šæ€§ä¸ä¸‹ä¸€æ­¥å»ºè®®ã€‚
éµå¾ªï¼šå¿…è¦æ—¶ç»™å‡ºå…¬å¼/ä»£ç ï¼›ä¸è¦ä½¿ç”¨è¡¨æƒ…ï¼›å¼•ç”¨å¤–éƒ¨ä¿¡æ¯æ—¶ç»™å‡ºæ¥æºã€‚
`;

async function testFollowUp(previousResponseId) {
  try {
    console.log("ğŸ”„ å‘é€ç»­èŠè¯·æ±‚...\n");
    console.log("ğŸ“Œ ä½¿ç”¨ä¸Šä¸€è½® Response ID:", previousResponseId);
    console.log("â”€".repeat(50));
    
    const followUpResponse = await client.responses.create({
      model: "gpt-5-mini",
      previous_response_id: previousResponseId,  // ç»§æ‰¿å¯¹è¯ä¸Šä¸‹æ–‡
      instructions: SYSTEM_PROMPT,  // ä»éœ€æ˜¾å¼ä¼ å…¥
      reasoning: { 
        effort: "low", 
        summary: "auto" 
      },
      input: [
        { 
          role: "user", 
          content: "ç”¨ç®€æ´è¯­å¥æ¦‚æ‹¬" 
        }
      ],
      tools: [{ type: "web_search" }],  // Enable web search
      store: true  // Store for future reference
    });

    console.log("\nâœ… ç»­èŠå“åº” ID:", followUpResponse.id);
    console.log("\nğŸ“ å“åº”å†…å®¹:");
    console.log("â”€".repeat(50));
    console.log(followUpResponse.output_text);
    console.log("â”€".repeat(50));
    
    // å¦‚æœæœ‰ reasoning summaryï¼Œæ‰“å°å‡ºæ¥
    if (followUpResponse.reasoning_summary) {
      console.log("\nğŸ’­ Reasoning Summary:");
      console.log(followUpResponse.reasoning_summary);
    }
    
    // æ‰“å°ä½¿ç”¨çš„ tokens
    if (followUpResponse.usage) {
      console.log("\nğŸ“Š Token ä½¿ç”¨æƒ…å†µ:");
      console.log(`  - Input tokens: ${followUpResponse.usage.input_tokens}`);
      console.log(`  - Output tokens: ${followUpResponse.usage.output_tokens}`);
      console.log(`  - Reasoning tokens: ${followUpResponse.usage.reasoning_tokens || 0}`);
      console.log(`  - Total tokens: ${followUpResponse.usage.total_tokens}`);
    }
    
    // ä¿å­˜å®Œæ•´å“åº”åˆ°æ–‡ä»¶
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `openai-followup-${timestamp}.json`;
    const filepath = path.join(process.cwd(), filename);
    
    const responseData = {
      timestamp: new Date().toISOString(),
      previous_response_id: previousResponseId,
      request: {
        model: "gpt-5-mini",
        previous_response_id: previousResponseId,
        instructions: SYSTEM_PROMPT,
        reasoning: { effort: "low", summary: "auto" },
        input: [{ role: "user", content: "ç”¨ç®€æ´è¯­å¥æ¦‚æ‹¬" }],
        tools: [{ type: "web_search" }],
        store: true
      },
      response: followUpResponse
    };
    
    await fs.writeFile(filepath, JSON.stringify(responseData, null, 2), 'utf-8');
    console.log(`\nğŸ’¾ ç»­èŠå“åº”å·²ä¿å­˜åˆ°: ${filename}`);
    
    return followUpResponse.id;  // è¿”å› ID ä¾›åç»­ä½¿ç”¨
    
  } catch (error) {
    console.error("âŒ é”™è¯¯:", error.message);
    if (error.response) {
      console.error("API å“åº”:", error.response.data);
    }
  }
}

// ä»å‘½ä»¤è¡Œå‚æ•°è·å– previous_response_idï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
const previousId = process.argv[2] || "resp_68ac8301b5508195b964c033a349c8a00995dc3199d3acfe";

console.log("========================================");
console.log("OpenAI Response API ç»­èŠæµ‹è¯•");
console.log("========================================\n");

// æ‰§è¡Œç»­èŠæµ‹è¯•
testFollowUp(previousId);